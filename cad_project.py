# -*- coding: utf-8 -*-
"""cad_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1FbECktU2_TaXkR1aPhAx8VDvucQbeRhQ

# New Section
"""



!pip install tensorflow-gpu

import tensorflow as tf
tf.__version__

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
from glob import glob
import matplotlib.pyplot as plt
# %matplotlib inline
from tensorflow.keras.layers import Input,Dense,Flatten
from tensorflow.keras.models import Model
from tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img
from tensorflow.keras.models import Sequential

iccad='/content/drive/My Drive/iccad1'

from keras.preprocessing import image 
from keras.applications.vgg16 import preprocess_input

datagen=ImageDataGenerator(rescale=1./255,validation_split=0.3)

train_generator=datagen.flow_from_directory(iccad,target_size=(224,224),subset='training',batch_size=32)
test_generator=datagen.flow_from_directory(iccad,target_size=(224,224),subset='validation',batch_size=32)

train_generator.image_shape

test_generator.image_shape

from keras.layers import Conv2D,Flatten,MaxPool2D

from keras.layers import Dropout
from keras.optimizers import RMSprop
from keras.layers import Activation
from keras.layers import MaxPooling2D
from keras.layers import InputLayer

model = Sequential()
model.add(InputLayer(input_shape=(224,224,3)))
model.add(Conv2D(50,(5,5),activation='relu',strides=(2,2),padding='same'))

model.add(Conv2D(25,(5,5),activation='relu',strides=(2,2),padding='same'))

model.add(MaxPool2D(2,2))

model.add(Flatten())

model.add(Dense(units=100,activation='relu'))
model.add(Dense(units=2,activation='softmax'))

model.summary()

model.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model_history=model.fit(train_generator,epochs=15,validation_data=test_generator)

plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('model_loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper left')
plt.show()
plt.savefig('iccad_loss.png')

plt.plot(model_history.history['accuracy'])
plt.plot(model_history.history['val_accuracy'])
plt.title('model_accuracy')
plt.ylabel('accuracy')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper right')
plt.show()

"""Second dataset"""

from google.colab import drive

import zipfile
with zipfile.ZipFile('/content/drive/MyDrive/iccad2.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/drive/MyDrive')

iccad2='/content/drive/MyDrive/iccad2'

datagen1=ImageDataGenerator(rescale=1./255,validation_split=0.3)

train_generator1=datagen1.flow_from_directory(iccad2,target_size=(224,224),subset='training',batch_size=32)
test_generator1=datagen1.flow_from_directory(iccad2,target_size=(224,224),subset='validation',batch_size=32)

train_generator1.image_shape

test_generator1.image_shape

model1= Sequential()
model1.add(InputLayer(input_shape=(224,224,3)))
model1.add(Conv2D(50,(5,5),activation='relu',strides=(2,2),padding='same'))

model1.add(Conv2D(25,(5,5),activation='relu',strides=(2,2),padding='same'))

model1.add(MaxPool2D(2,2))

model1.add(Flatten())

model1.add(Dense(units=100,activation='relu'))
model1.add(Dense(units=2,activation='softmax'))

model1.summary()

model1.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model_history1=model1.fit(train_generator1,epochs=10,validation_data=test_generator1)

plt.plot(model_history1.history['loss'])
plt.plot(model_history1.history['val_loss'])
plt.title('model_loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper left')
plt.show()

plt.plot(model_history1.history['accuracy'])
plt.plot(model_history1.history['val_accuracy'])
plt.title('model_accuracy')
plt.ylabel('accuracy')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper right')
plt.show()

"""Third Dataset

"""

import zipfile
with zipfile.ZipFile('/content/drive/MyDrive/iccad3.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/drive/MyDrive')

iccad3='/content/drive/MyDrive/iccad3'

datagen2=ImageDataGenerator(rescale=1./255,validation_split=0.3)

train_generator2=datagen2.flow_from_directory(iccad3,target_size=(224,224),subset='training',batch_size=32)
test_generator2=datagen2.flow_from_directory(iccad3,target_size=(224,224),subset='validation',batch_size=32)

model2 = Sequential()
model2.add(InputLayer(input_shape=(224,224,3)))
model2.add(Conv2D(50,(5,5),activation='relu',strides=(2,2),padding='same'))

model2.add(Conv2D(25,(5,5),activation='relu',strides=(2,2),padding='same'))

model2.add(MaxPool2D(2,2))

model2.add(Flatten())

model2.add(Dense(units=100,activation='relu'))
model2.add(Dense(units=2,activation='softmax'))

model2.summary()

model2.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model_history2=model2.fit(train_generator2,epochs=10,validation_data=test_generator2)

plt.plot(model_history2.history['loss'])
plt.plot(model_history2.history['val_loss'])
plt.title('model_loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper left')
plt.show()

plt.plot(model_history2.history['accuracy'])
plt.plot(model_history2.history['val_accuracy'])
plt.title('model_accuracy')
plt.ylabel('accuracy')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper right')
plt.show()

"""Fourth dataset

"""

import zipfile
with zipfile.ZipFile('/content/drive/MyDrive/iccad4.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/drive/MyDrive')

iccad4='/content/drive/MyDrive/iccad4'

datagen3=ImageDataGenerator(rescale=1./255,validation_split=0.3)

train_generator3=datagen3.flow_from_directory(iccad4,target_size=(224,224),subset='training',batch_size=32)
test_generator3=datagen3.flow_from_directory(iccad4,target_size=(224,224),subset='validation',batch_size=32)

model3 = Sequential()
model3.add(InputLayer(input_shape=(224,224,3)))
model3.add(Conv2D(50,(5,5),activation='relu',strides=(2,2),padding='same'))

model3.add(Conv2D(25,(5,5),activation='relu',strides=(2,2),padding='same'))
model3.add(MaxPool2D(2,2))

model3.add(Flatten())

model3.add(Dense(units=100,activation='relu'))
model3.add(Dense(units=2,activation='softmax'))

model3.summary()

model3.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model_history3=model3.fit(train_generator3,epochs=10,validation_data=test_generator3)



plt.plot(model_history3.history['loss'])
plt.plot(model_history3.history['val_loss'])
plt.title('model_loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper left')
plt.show()

plt.plot(model_history3.history['accuracy'])
plt.plot(model_history3.history['val_accuracy'])
plt.title('model_accuracy')
plt.ylabel('accuracy')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper right')
plt.show()

"""Fifth Dataset"""

import zipfile
with zipfile.ZipFile('/content/drive/MyDrive/iccad5.zip', 'r') as zip_ref:
    zip_ref.extractall('/content/drive/MyDrive')

iccad5='/content/drive/MyDrive/iccad5'

datagen4=ImageDataGenerator(rescale=1./255,validation_split=0.3)

train_generator4=datagen4.flow_from_directory(iccad5,target_size=(224,224),subset='training',batch_size=32)
test_generator4=datagen4.flow_from_directory(iccad5,target_size=(224,224),subset='validation',batch_size=32)

model4 = Sequential()
model4.add(InputLayer(input_shape=(224,224,3)))
model4.add(Conv2D(50,(5,5),activation='relu',strides=(2,2),padding='valid'))

model4.add(Conv2D(25,(5,5),activation='relu',strides=(2,2),padding='valid'))
model4.add(MaxPool2D(2,2))

model4.add(Flatten())

model4.add(Dense(units=100,activation='relu'))
model4.add(Dense(units=2,activation='softmax'))

model4.summary()

model4.compile(loss='categorical_crossentropy',
              optimizer='adam',
              metrics=['accuracy'])

model_history4=model4.fit(train_generator4,epochs=10,validation_data=test_generator4)

plt.plot(model_history4.history['loss'])
plt.plot(model_history4.history['val_loss'])
plt.title('model_loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper left')
plt.show()

plt.plot(model_history4.history['accuracy'])
plt.plot(model_history4.history['val_accuracy'])
plt.title('model_accuracy')
plt.ylabel('accuracy')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper right')
plt.show()

"""DMS project"""

!unzip /content/drive/MyDrive/Dataset.zip

data=pd.read_csv('/content/Dataset/emergency_classification.csv')

seed=42
rng=np.random.RandomState(seed)

data.head()

data['emergency_or_not'].value_counts()

x=[]
for img_name in data.image_names:
  img=plt.imread('/content/Dataset/images/'+img_name)
  
  x.append(img)
X=np.array(x)
y=data.emergency_or_not.values

X.shape

X=X/X.max()

from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

x_train,x_valid,y_train,y_valid=train_test_split(X,y,test_size=0.3,random_state=42)

x_train.shape,y_train.shape,x_valid.shape,y_valid.shape

from keras.layers import BatchNormalization

model=Sequential()
model.add(InputLayer(input_shape=(224,224,3)))
model.add(Conv2D(50,(5,5),activation='relu',strides=(1,1),padding='valid'))
model.add(MaxPool2D(pool_size=(2,2),padding='valid'))
model.add(Conv2D(50,(5,5),activation='relu',strides=(1,1),padding='valid'))
model.add(MaxPool2D(pool_size=(4,4),padding='valid'))
model.add(Flatten())
model.add(Dense(units=100,activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(rate=0.6))
model.add(Dense(units=100,activation='relu'))
model.add(BatchNormalization())
model.add(Dropout(rate=0.6))
model.add(Dense(units=1,activation='sigmoid'))

model.compile(loss='binary_crossentropy',optimizer='adam',metrics='accuracy')

model.summary()

model_history=model.fit(x_train,y_train,epochs=50,batch_size=128,validation_data=(x_valid,y_valid))

plt.plot(model_history.history['loss'])
plt.plot(model_history.history['val_loss'])
plt.title('model_loss')
plt.ylabel('loss')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper left')
plt.show()

plt.plot(model_history.history['accuracy'])
plt.plot(model_history.history['val_accuracy'])
plt.title('model_accuracy')
plt.ylabel('accuracy')
plt.xlabel('epochs')
plt.legend(['train','validation'],loc='upper right')
plt.show()

print('accuracy of model',accuracy_score(y_train,model.predict_classes(x_train)))

print('accuracy of validation set',accuracy_score(y_valid,model.predict_classes(x_valid)))

